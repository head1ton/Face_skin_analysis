import cv2
import dlib
import numpy as np
import streamlit as st
import time

# ========== ì–¼êµ´ ë¶„ì„ í´ë˜ìŠ¤ ==========
class FaceSkinAnalyzer:
    def __init__(self):
        self.parts = ['forehead', 'eyes', 'nose', 'philtrum', 'chin', 'cheeks']

    def analyze_frame(self, frame, progress_callback=None):
        h, w, _ = frame.shape
        result = {}
        for i, part in enumerate(self.parts):
            time.sleep(0.2)
            if progress_callback:
                progress_callback((i + 1) / len(self.parts))
            result[part] = self.fake_analysis(part)
        return result

    def fake_analysis(self, part):
        import random
        options = {
            'forehead': ['ì£¼ë¦„ ìˆìŒ', 'í”¼ë¶€ í†¤ ê³ ë¦„', 'ëª¨ê³µ ì•½ê°„ ë³´ì„'],
            'eyes': ['ëˆˆê°€ ì£¼ë¦„ ìˆìŒ', 'ë‹¤í¬ì„œí´ ë³´ì„', 'í”¼ë¶€ ë°ìŒ'],
            'nose': ['ë¸”ë™í—¤ë“œ ìˆìŒ', 'ìœ ë¶„ ë§ìŒ', 'í”¼ë¶€ ê¹¨ë—í•¨'],
            'philtrum': ['ìƒ‰ì†Œ ì¹¨ì°© ì•½ê°„', 'ëª¨ê³µ ë³´ì„', 'ê· ì¼í•œ í”¼ë¶€'],
            'chin': ['ì—¬ë“œë¦„ í”ì  ìˆìŒ', 'í”¼ë¶€í†¤ ë¶ˆê· ì¼', 'ê¹¨ë—í•œ í”¼ë¶€'],
            'cheeks': ['ëª¨ê³µ í¼', 'í˜ˆê´€ ë¹„ì¹¨', 'íƒ„ë ¥ ì¢‹ìŒ']
        }
        return random.choice(options[part])

    def recommend_products(self, result):
        recs = []
        if "forehead" in result or "eye_area" in result:
            recs.append("ì£¼ë¦„ ê°œì„  í¬ë¦¼")
        if "nose" in result:
            recs.append("ëª¨ê³µ ì¶•ì†Œ ì„¸ëŸ¼")
        if "mouth" in result:
            recs.append("ìœ ë¶„ ì¡°ì ˆ í¬ë¦¼")
        return recs

# ========== ì–¼êµ´ ëœë“œë§ˆí¬ í‘œì‹œ ==========
def draw_landmarks(frame, landmarks):
    for n in range(0, 68):
        x = landmarks.part(n).x
        y = landmarks.part(n).y
        cv2.circle(frame, (x, y), 2, (255, 0, 0), -1)

# ========== ìŠ¬ë¼ì´ë”© ì œìŠ¤ì²˜ ==========
def sliding_gesture_on_single_frame(frame):
    import math

    h, w, _ = frame.shape
    base_frame = frame.copy()
    num_lines = 40
    step = w // num_lines
    line_color = (0, 255, 0)
    line_thickness = 3

    placeholder = st.empty()

    for i in range(num_lines):
        temp = base_frame.copy()

        # ì„  ìœ„ì¹˜ ê³„ì‚°
        x = int((i / num_lines) * w)

        # ë°˜íˆ¬ëª… ì„  ì˜¤ë²„ë ˆì´
        overlay = temp.copy()
        cv2.line(overlay, (x, 0), (x, h), line_color, line_thickness)
        alpha = 0.4
        cv2.addWeighted(overlay, alpha, temp, 1 - alpha, 0, temp)

        # íë¦¼ íš¨ê³¼ + í…ìŠ¤íŠ¸
        if i % 2 == 0:
            temp = cv2.GaussianBlur(temp, (3, 3), 0)

        progress_percent = int((i / num_lines) * 100)
        cv2.putText(temp, f"Analyzing... {progress_percent}%", (10, h - 20),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA)

        # ì´ë¯¸ì§€ í‘œì‹œ
        placeholder.image(cv2.cvtColor(temp, cv2.COLOR_BGR2RGB), channels="RGB", use_container_width=True)
        time.sleep(0.03)

    # ë§ˆì§€ë§‰ì— ê¹¨ë—í•œ ì›ë³¸ ì´ë¯¸ì§€ë¡œ ë‹¤ì‹œ ë®ì–´ì“°ê¸°
    placeholder.image(cv2.cvtColor(base_frame, cv2.COLOR_BGR2RGB), channels="RGB", use_container_width=True)

    st.session_state.captured_frame = None
    return base_frame





# ========== Streamlit ì•± ì‹œì‘ ==========
# st.set_page_config(layout="wide")
st.title("ğŸ“· ì‹¤ì‹œê°„ ì–¼êµ´ í”¼ë¶€ ë¶„ì„")

analyzer = FaceSkinAnalyzer()
predictor_path = "shape_predictor_68_face_landmarks.dat"

try:
    detector = dlib.get_frontal_face_detector()
    predictor = dlib.shape_predictor(predictor_path)
except:
    st.error("âš ï¸ 'shape_predictor_68_face_landmarks.dat' íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")

if 'captured_frame' in st.session_state:
    st.session_state.captured_frame = None


st.session_state.captured_frame = None

frame_window = st.empty()

capture_btn = st.button("ğŸ“¸ ì–¼êµ´ ìº¡ì²˜ ë° í”¼ë¶€ ë¶„ì„ ì‹œì‘")

captured = False


col1, col2 = st.columns(2)

with col1:

    # ========== ì‹¤ì‹œê°„ ì˜ìƒ ì²˜ë¦¬ ==========
    cap = cv2.VideoCapture(0)
    if capture_btn and not captured:
        captured = False

    while True:


        ret, frame = cap.read()
        if not ret:
            st.error("âŒ ì¹´ë©”ë¼ ì—°ê²° ì‹¤íŒ¨")
            break

        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        faces = detector(gray)

        for face in faces:
            landmarks = predictor(gray, face)
            draw_landmarks(frame, landmarks)

        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        frame_window.image(frame_rgb, channels="RGB", use_container_width=True)

        if capture_btn and not captured:
            captured = True
            st.session_state.captured_frame = frame.copy()
            st.success("âœ… ì–¼êµ´ ìº¡ì²˜ ì™„ë£Œ!")

            break

    # cap.release()

with col2:
    # ========== ìº¡ì²˜ ì´ë¯¸ì§€ ë¶„ì„ ==========
    if captured and st.session_state.captured_frame is not None:
        st.subheader("ğŸ¬ ìŠ¬ë¼ì´ë”© ìº¡ì²˜ ì• ë‹ˆë©”ì´ì…˜")
        final_frame = sliding_gesture_on_single_frame(st.session_state.captured_frame)

        st.subheader("ğŸ” í”¼ë¶€ ë¶„ì„ ì§„í–‰ ì¤‘...")
        progress = st.progress(0)
        result = analyzer.analyze_frame(final_frame, progress_callback=progress.progress)

        st.subheader("ğŸ“Š ë¶„ì„ ê²°ê³¼")
        for part, analysis in result.items():
            st.write(f"ğŸ“Œ **{part.upper()}**: {analysis}")

        st.subheader("ğŸ’¡ ì¶”ì²œ í™”ì¥í’ˆ")
        for rec in analyzer.recommend_products(result):
            st.success(f"ğŸ§´ {rec}")


print('captured: ', captured)
print('capture_btn: ', capture_btn)
print('captured_frame: ', st.session_state.captured_frame)